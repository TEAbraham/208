{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8a4bed-77c8-4ac3-933a-538917c85c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "def wrap_latex_if_needed(text):\n",
    "    stripped = text.strip()\n",
    "    if re.match(r\"^[-+*/()=0-9a-zA-Z.\\\\^ ]+$\", stripped):\n",
    "        return f\"$$ {stripped} $$\"\n",
    "    return f\"$ {stripped} $\"\n",
    "\n",
    "def convert_mml_to_latex(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    for math in soup.select(\"mjx-assistive-mml\"):\n",
    "        if math.has_attr(\"alttext\"):\n",
    "            latex = wrap_latex_if_needed(math[\"alttext\"].strip())\n",
    "            math.insert_before(latex)\n",
    "            math.decompose()\n",
    "    return soup.get_text(\" \", strip=True)\n",
    "\n",
    "tom = [\"Easy\", \"Medium\", \"Hard\"]\n",
    "collegeboard = [\"Emerging\", \"Proficient\", \"Advanced\"]\n",
    "\n",
    "difficulty = dict(zip(collegeboard, tom))\n",
    "\n",
    "# Setup and login instructions\n",
    "options = Options()\n",
    "options.add_argument('--start-maximized')\n",
    "driver = webdriver.Chrome(service=Service(), options=options)\n",
    "\n",
    "# Open the desired webpage\n",
    "driver.get('https://apclassroom.collegeboard.org/33/question_bank/questions')\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "# Enter the email address\n",
    "email_input = wait.until(EC.element_to_be_clickable((By.ID, 'input28')))\n",
    "email_input.send_keys('tabraham@thsrocks.us')\n",
    "email_input.send_keys(u'\\ue007')  # Press Enter key\n",
    "\n",
    "select = wait.until(EC.element_to_be_clickable((By.XPATH,'/html/body/div[2]/main/div[2]/div/div/div[2]/form/div[2]/div/div[2]/div[2]/div[2]/a')))\n",
    "select.send_keys(u'\\ue007')  # Press Enter key\n",
    "\n",
    "# Wait and input the password\n",
    "password_input = wait.until(EC.element_to_be_clickable((By.ID, 'input83')))\n",
    "password_input.send_keys('Ayrab711!')\n",
    "password_input.send_keys(u'\\ue007')  # Press Enter key\n",
    "\n",
    "# MCQ Page\n",
    "time.sleep(10)  # Adjust time as needed\n",
    "driver.get('https://apclassroom.collegeboard.org/33/question_bank/questions?tags=%2722737%27%3A%21%28356755%29')\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "select = wait.until(EC.element_to_be_clickable((By.XPATH,'/html/body/div[1]/div/div[4]/div/div[2]/main/div[4]/div[2]/div[2]/div[1]/div/div/table/tbody/tr[1]/td[1]/span/div/a')))\n",
    "select.send_keys(u'\\ue007')  # Press Enter key\n",
    "\n",
    "select = wait.until(EC.element_to_be_clickable((By.XPATH,'/html/body/div[1]/div/div[4]/div/div[2]/main/div[4]/div[2]/div[5]/div/div/div[2]/div/div[2]/div/div[2]/div[1]/span')))\n",
    "select.click()  # Press Enter key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07e800f-e04d-4462-8032-8b026444dd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrape_question(driver, wait):\n",
    "    \n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.ItemMetadata\")))\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.lrn-assess-content\")))\n",
    "    \n",
    "    output = {\n",
    "    \"question_id\": \"\",\n",
    "    \"unit\": \"\",\n",
    "    \"topics\": [],    \n",
    "    \"title\": \"\",\n",
    "    \"difficulty\": \"\",\n",
    "    \"question_text\": \"\",\n",
    "    \"image_files\": [],\n",
    "    \"tables\": [],\n",
    "    \"choices\": [],\n",
    "    \"correct_answer\": \"\",\n",
    "    \"solution\": \"\",\n",
    "    \"explanations\": [],\n",
    "    \"tags\": [],\n",
    "    }\n",
    "\n",
    "    title_words = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[4]/div/div[2]/main/div[4]/div[2]/div[5]/div/div/div[1]/h2/span/span').text\n",
    "    meta = driver.find_element(By.CSS_SELECTOR, \"div.ItemMetadata\")\n",
    "    view = driver.find_element(By.CSS_SELECTOR, \"div.lrn-assess-content\")\n",
    "    ul = meta.find_elements(By.TAG_NAME, \"ul\")\n",
    "    item_details = ul[0].text.split('\\n')\n",
    "    unit_topic = ul[1].text.split('\\n')\n",
    "    diff = ul[-1].text.split(' ')[2]\n",
    "    stimulus = item_details[1].split(\" \")[2]\n",
    "    if stimulus == \"Data Set\":\n",
    "        return\n",
    "    folder = 'unit'+unit_topic[0][0]\n",
    "    question_id = f\"question-{len([f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]):03d}\"\n",
    "    choices = driver.find_elements(By.CSS_SELECTOR, \"li.lrn-mcq-option\")\n",
    "    correct = driver.find_element(By.CSS_SELECTOR, \"div.teacher-item-preview\")\n",
    "    distractors = correct.find_elements(By.CSS_SELECTOR, \"p.rationale_paragraph\")\n",
    "    \n",
    "    output['question_id'] = question_id\n",
    "    output['unit'] = unit_topic[0]\n",
    "    output['topics'] = unit_topic[1:]\n",
    "    output['title'] = \" \".join(title_words.split(\" \")[1:])\n",
    "    output['difficulty'] = difficulty[diff]\n",
    "    output['question_text'] = \"\\n\".join([convert_mml_to_latex(p.text) for p in driver.find_elements(By.CSS_SELECTOR, \"p.passage_para\") + driver.find_elements(By.CSS_SELECTOR, \"p.stem_paragraph\")])\n",
    "    letters = ['A', 'B', 'C', 'D', 'E']\n",
    "    for choice, letter in zip(choices, letters):\n",
    "        text = convert_mml_to_latex(choice.find_element(By.CSS_SELECTOR, \"p.choice_paragraph\").text)\n",
    "        output['choices'].append({\"letter\": letter, \"text\": text})\n",
    "    output['correct_answer'] = driver.execute_script(\"return arguments[0].textContent;\", correct.find_element(By.TAG_NAME, \"h3\"))\n",
    "    for d in distractors:\n",
    "        text = convert_mml_to_latex(d.text)\n",
    "        output['solution'] += text\n",
    "    for d in distractors:\n",
    "        text = convert_mml_to_latex(driver.execute_script(\"return arguments[0].textContent;\", d))\n",
    "        output['explanations'].append(text)\n",
    "    output['tags'] = ul[7].text.split('\\n')\n",
    "    \n",
    "    image_folder = os.path.join(folder, \"images\")\n",
    "    os.makedirs(image_folder, exist_ok=True)\n",
    "    \n",
    "\n",
    "    tables = driver.find_elements(By.CSS_SELECTOR, \"div.table_wrapper\")\n",
    "    for table in tables:\n",
    "        html = table.get_attribute(\"innerHTML\")\n",
    "        output[\"tables\"].append(convert_mml_to_latex(html))\n",
    "        \n",
    "    images = view.find_elements(By.TAG_NAME, \"img\")\n",
    "    for i, img in enumerate(images):\n",
    "        img_url = img.get_attribute(\"src\")\n",
    "        ext = os.path.splitext(urlparse(img_url).path)[1] or \".png\"\n",
    "        local_filename = f\"{question_id}-img{i+1}{ext}\"\n",
    "        local_path = os.path.join(image_folder, local_filename)\n",
    "\n",
    "        try:\n",
    "            img_data = requests.get(img_url).content\n",
    "            with open(local_path, \"wb\") as f:\n",
    "                f.write(img_data)\n",
    "            output[\"image_files\"].append(f\"images/{local_filename}\")\n",
    "            print(f\"üñº Downloaded: {local_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Image download failed: {e}\")\n",
    "            \n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    out_path = f\"{folder}/{question_id}.json\"\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"‚úÖ Saved {question_id} to {out_path}\")\n",
    "    \n",
    "    next_btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[data-test-id='next-button']\")))\n",
    "    next_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a176c-3740-47a3-a77a-4d480ad2f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "total_questions = 967\n",
    "while total_questions is None or i <= total_questions:\n",
    "    question_id = f\"question-{i:03d}\"\n",
    "    print(f\"\\nüß† Scraping {question_id} of {total_questions if total_questions else '???'}\")\n",
    "    success = scrape_question(driver, wait)\n",
    "\n",
    "    if not success:\n",
    "        print(\"‚úÖ Finished scraping all questions or hit end.\")\n",
    "        break\n",
    "\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
