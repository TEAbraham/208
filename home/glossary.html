<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mr.&nbsp;Abraham">

<title>AP Statistics Glossary</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="Glossary_files/libs/clipboard/clipboard.min.js"></script>
<script src="Glossary_files/libs/quarto-html/quarto.js"></script>
<script src="Glossary_files/libs/quarto-html/popper.min.js"></script>
<script src="Glossary_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Glossary_files/libs/quarto-html/anchor.min.js"></script>
<link href="Glossary_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Glossary_files/libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Glossary_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Glossary_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Glossary_files/libs/bootstrap/bootstrap-c0367b04c37547644fece4185067e4a7.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">AP Statistics Glossary</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Mr.&nbsp;Abraham </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="unit-1" class="level1">
<h1>Unit 1</h1>
<p><strong>statistics</strong><br>
The science and art of collecting, analyzing, and drawing conclusions from data.</p>
<p><strong>individual</strong><br>
An object described by a set of data. Individuals can be people, animals, or things.</p>
<p><strong>variable</strong><br>
Any characteristic of an individual. A variable can take different values for different individuals.</p>
<p><strong>categorical variable</strong><br>
A variable that assigns labels that place each individual into a particular group, called a category.</p>
<p><strong>quantitative variable</strong><br>
Variable that takes number values that are quantities—counts or measurements.</p>
<p><strong>distribution</strong><br>
Tells what values a variable takes and how often it takes each value.</p>
<p><strong>frequency table</strong><br>
Table that shows the number of individuals having each value.</p>
<p><strong>relative frequency table</strong><br>
Table that shows the proportion or percentage of individuals having each value.</p>
<p><strong>bar graph</strong><br>
Graph used to display the distribution of a categorical variable. The horizontal axis of a bar graph identifies the categories being compared. The heights of the bars show the frequency or relative frequency for each value of the categorical variable. The graph is drawn with blank spaces between the bars to separate the categories being compared.</p>
<p><strong>pie chart</strong><br>
Graph that shows the distribution of a categorical variable as a “pie” whose slices have areas proportional to the category frequencies or relative frequencies. A pie chart must include all the categories that make up a whole.</p>
<p><strong>side-by-side bar graph</strong><br>
Graph used to compare the distribution of a categorical variable in each of two or more groups. For each value of the categorical variable, there is a bar corresponding to each group. The height of each bar is determined by the count or percentage of individuals in the group with that value.</p>
<p><strong>discrete variable</strong><br>
A quantitative variable that takes a countable set of possible values with gaps between them on the number line.</p>
<p><strong>continuous variable</strong><br>
A quantitative variable that can take any value in an interval on the number line.</p>
<p><strong>dotplot</strong><br>
A graph that displays the distribution of a quantitative variable by plotting each data value as a dot above its location on a number line.</p>
<p><strong>roughly symmetric</strong><br>
When the right side of a graph of quantitative data, which contains the half of the observations with the largest values, is approximately a mirror image of the left side.</p>
<p><strong>skewed to the left</strong><br>
When the left side of a graph of quantitative data, which contains the half of the observations with the smallest values, is much longer than the right side.</p>
<p><strong>skewed to the right</strong><br>
When the right side of a graph of quantitative data, which contains the half of the observations with the largest values, is much longer than the left side.</p>
<p><strong>approximately uniform</strong><br>
A distribution in which the frequency (relative frequency) of each possible value is about the same.</p>
<p><strong>stemplot</strong><br>
Graph that displays the distribution of a quantitative variable while including the actual numerical values in the graph. Each data value is separated into two parts: a stem, which consists of the leftmost digits, and a leaf, consisting of the final digit. The stems are ordered from least to greatest and arranged in a vertical column. The leaves are arranged in increasing order out from the appropriate stems.</p>
<p><strong>histogram</strong><br>
Graph that displays the distribution of a quantitative variable by showing each interval of values as a bar. The heights of the bars show the frequencies or relative frequencies of values in each interval.</p>
<p><strong>median</strong><br>
The midpoint of a distribution of quantitative data; the number such that about half the observations are smaller and about half are larger. To find the median, arrange the data values from smallest to largest. If the number n of data values is odd, the median is the middle value in the ordered list. If the number n of data values is even, use the average of the two middle values in the ordered list as the median.</p>
<p><strong>mean</strong><br>
The average of all the individual data values in a distribution of quantitative data. To find the mean, add all the values and divide by the total number of data values.</p>
<p><strong>statistic</strong><br>
Number that describes some characteristic of a sample.</p>
<p><strong>parameter</strong><br>
A number that describes some characteristic of a population.</p>
<p><strong>resistant</strong><br>
A statistical measure that isn’t affected much by extreme values.</p>
<p><strong>range</strong><br>
The distance between the minimum value and the maximum value of a distribution of quantitative data. That is, range = maximum - minimum.</p>
<p><strong>standard deviation</strong><br>
Measures the typical distance of the values in a distribution from the mean. It is calculated by finding an “average” of the squared deviations of the individual data values from the mean, and then taking the square root.</p>
<p><strong>quartiles</strong><br>
The quartiles of a distribution divide an ordered data set into four groups having roughly the same number of values.</p>
<p><strong>first quartile Q1</strong></p>
<p>If the observations in a data set are arranged left to right from smallest to largest, the first quartile Q1 is the median of the data values that are to the left of the median in the ordered list.</p>
<p><strong>third quartile Q3</strong></p>
<p>If the observations in a data set are arranged left to right from smallest to largest, the third quartile Q3 is the median of the data values that are to the right of the median in the ordered list.</p>
<p><strong>interquartile range (IQR)</strong></p>
<p>The distance between the first and third quartiles of a distribution of quantitative data. In symbols, IQR = Q3 - Q1.</p>
<p><strong>five-number summary</strong><br>
The minimum, first quartile 1Q, median, third quartile 3Q, and maximum of a distribution of quantitative data.</p>
<p><strong>boxplot</strong><br>
A visual representation of the five-number summary of a distribution of quantitative data. The box spans the quartiles and shows the variability of the middle half of the distribution. The median is marked with a vertical line segment in the box. Lines extend from the ends of the box to the smallest and largest observations that are not outliers. Outliers are marked with a special symbol such as an asterisk (*).</p>
<p><strong>percentile</strong><br>
The pth percentile of a distribution is the value with p% of observations less than or equal to it.</p>
<p><strong>standardized score (z-score)</strong></p>
<p>For an individual value in a distribution, the standardized score (z-score) tells us how many standard deviations from the mean the value falls, and in what direction.</p>
<p><strong>cumulative relative frequency graph</strong><br>
A cumulative relative frequency graph plots a point corresponding to the percentile of a given value in a distribution of quantitative data. Consecutive points are then connected with a line segment to form the graph.</p>
<p><strong>normal distribution</strong><br>
Distribution described by a normal curve. Any normal distribution is completely specified by two parameters, its mean μ and standard deviation σ. The mean of a normal distribution is at the center of the symmetric normal curve. The standard deviation is the distance from the center to the change-of-curvature points on either side.</p>
<p><strong>normal curve</strong><br>
Important kind of curve that is symmetric, single-peaked, and mound-shaped.</p>
<p><strong>empirical rule</strong><br>
In a normal distribution with mean μ and standard deviation σ (a) about 68% of the values fall within 1 σ of the mean μ, (b) about 95% of the values fall within 2 σ of μ and (c) about 99.7% of the values fall within 3 σ values of μ.</p>
<p><strong>standard normal distribution</strong><br>
Normal distribution with mean 0 and standard deviation 1.</p>
</section>
<section id="unit-2" class="level1">
<h1>Unit 2</h1>
<p><strong>regression line</strong><br>
Line that models how a response variable y changes as an explanatory variable x changes. Regression lines are expressed in the form ŷ = a + bx, where ŷ is the predicted value of y for a given value of x.</p>
<p><strong>correlation r</strong></p>
<p>Gives the direction and measures the strength of the linear relationship between two quantitative variables.</p>
<p><strong>negative association</strong><br>
When values of one variable tend to decrease as the values of the other variable increase.</p>
<p><strong>no association</strong><br>
A relationship between two variables where knowing the value of one variable does not help predict the value of the other variable.</p>
<p><strong>scatterplot</strong><br>
Graph that shows the relationship between two quantitative variables measured on the same individuals. The values of one variable appear on the horizontal axis, and the values of the other variable appear on the vertical axis. Each individual in the data appears as a point in the graph.</p>
<p><strong>positive association</strong><br>
When values of one variable tend to increase as the values of the other variable increase.</p>
<p><strong>association</strong><br>
A relationship between two variables in which knowing the value of one variable helps predict the value of the other. If knowing the value of one variable does not help predict the value of the other, there is no association between the variables.</p>
<p><strong>mosaic plot</strong><br>
A modified segmented bar graph in which the width of each bar is proportional to the number of individuals in the corresponding category.</p>
<p><strong>segmented bar graph</strong><br>
Graph that displays the distribution of a categorical variable as segments of a bar, with the area of each segment proportional to the number of individuals in the corresponding category.</p>
<p><strong>conditional relative frequency</strong><br>
Gives the percentage or proportion of individuals that have a specific value for one categorical variable among a group of individuals that share the same value of another categorical variable (the condition).</p>
<p><strong>joint relative frequency</strong><br>
Gives the percent or proportion of individuals in a two-way table that have a specific value for one categorical variable and a specific value for another categorical variable.</p>
<p><strong>marginal relative frequency</strong><br>
Gives the percentage or proportion of individuals in a two-way table that have a specific value for one categorical variable.</p>
<p><strong>two-way table</strong><br>
Table of counts or relative frequencies that summarizes data on the relationship between two categorical variables for some group of individuals.</p>
<p><strong>explanatory variable</strong><br>
Variable that may help predict or explain changes in a response variable.</p>
<p><strong>response variable</strong><br>
Variable that measures the outcome of a study.</p>
<p><strong>extrapolation</strong><br>
Use of a regression model for prediction outside the interval of x values used to obtain the model. The further we extrapolate, the less reliable the predictions become.</p>
<p><strong>residual</strong><br>
Difference between an actual value of y and the value of</p>
<p>y predicted by the regression line: residual = actual y − predicted y = y − ŷ.</p>
<p><strong>y intercept</strong></p>
<p>In the regression equation ŷ = a + bx, the y intercept a is the predicted value of y when x = 0.</p>
<p><strong>slope</strong><br>
In the regression equation ŷ = a + bx, the slope b is the amount by which the predicted value of y changes when x increases by 1 unit.</p>
<p><strong>least-squares regression line</strong><br>
The line that makes the sum of the squared residuals as small as possible.</p>
<p><strong>residual plot</strong><br>
A scatterplot that displays the residuals on the vertical axis and the explanatory variable (or the predicted values) on the horizontal axis. Residual plots help us assess whether a regression model is appropriate.</p>
<p><strong>coefficient of determination r²</strong></p>
<p>A measure of the percent reduction in the sum of squared residuals when using the least-squares regression line to make predictions, rather than the mean value of y. In other words, r² measures the proportion or percentage of the variability in the response variable that is accounted for by the explanatory variable in the linear model.</p>
<p><strong>standard deviation of the residuals (s)</strong></p>
<p>s measures the typical distance between the actual y values and the predicted y values.</p>
<p><strong>high leverage</strong><br>
Points that have much larger or much smaller x values than the other points in a bivariate quantitative data set.</p>
<p><strong>outlier</strong><br>
Individual value that falls outside the overall pattern of a distribution of quantitative data.</p>
<p><strong>influential point</strong><br>
Any point that, if removed, substantially changes the slope, y intercept, correlation, coefficient of determination, or standard deviation of the residuals.</p>
</section>
<section id="unit-3" class="level1">
<h1>Unit 3</h1>
<p><strong>population</strong><br>
In a statistical study, the entire group of individuals we want information about.</p>
<p><strong>census</strong><br>
Study that collects data from every individual in the population.</p>
<p><strong>sample</strong><br>
Subset of individuals in the population from which we collect data.</p>
<p><strong>sample survey</strong><br>
Study that collects data from a sample to learn about the population from which the sample was selected.</p>
<p><strong>random sampling</strong><br>
Using a chance process to determine which members of a population are chosen for the sample.</p>
<p><strong>observational study</strong><br>
Study that observes individuals and measures variables of interest but does not attempt to influence the responses.</p>
<p><strong>retrospective observational study</strong><br>
An observational study that uses existing data for a sample of individuals.</p>
<p><strong>prospective observational study</strong><br>
An observational study that tracks individuals into the future.</p>
<p><strong>experiment</strong><br>
A study in which researchers deliberately impose treatments on experimental units to measure their responses.</p>
<p><strong>simple random sample (SRS)</strong><br>
Sample chosen in such a way that every group of n individuals in the population has an equal chance to be selected as the sample.</p>
<p><strong>sampling with replacement</strong><br>
When an individual from a population can be selected more than once when choosing a sample.</p>
<p><strong>sampling without replacement</strong><br>
When an individual from a population can be selected only once when choosing a sample.</p>
<p><strong>strata</strong><br>
Groups of individuals in a population that share characteristics thought to be associated with the variables being measured in a study. The singular form of strata is stratum.</p>
<p><strong>stratified random sample</strong><br>
A sample selected by dividing the population into non-overlapping groups (strata) of individuals that share characteristics thought to be associated with the variables being measured in a study, selecting an SRS from each stratum, and combining the SRSs into one overall sample.</p>
<p><strong>cluster</strong><br>
A group of individuals in the population that are located near each other.</p>
<p><strong>cluster sample</strong><br>
A sample selected by dividing the population into non-overlapping groups (clusters) of individuals that are located near each other, randomly choosing clusters, and including each member of the selected clusters in the sample.</p>
<p><strong>systematic random sample</strong><br>
A sample selected by choosing individuals from an ordered arrangement of the population by randomly selecting one of the first k individuals and choosing every kth individual thereafter.</p>
<p><strong>convenience sample</strong><br>
A sample that consists of individuals from the population who are easy to reach. Convenience sampling leads to bias when the members of the sample differ from the population in ways that affect their responses.</p>
<p><strong>bias</strong><br>
The design of a statistical study shows bias if it is very likely to underestimate or very likely to overestimate the value you want to know.</p>
<p><strong>voluntary response sample</strong><br>
A sample that consists of people who choose to be in the sample by responding to a general invitation. Voluntary response samples are sometimes called self-selected samples. Voluntary response sampling leads to voluntary response bias when the members of the sample differ from the population in ways that affect their responses.</p>
<p><strong>undercoverage</strong><br>
Occurs when some members of the population are less likely to be chosen or cannot be chosen in a sample. Undercoverage bias occurs when the underrepresented individuals differ from the population in ways that affect their responses.</p>
<p><strong>nonresponse</strong><br>
Occurs when an individual chosen for the sample can’t be contacted or refuses to participate. Nonresponse bias occurs when the individuals who can’t be contacted or who refuse to participate differ from the population in ways that affect their responses.</p>
<p><strong>response bias</strong><br>
Occurs when there is a consistent pattern of inaccurate responses to a survey question. Includes bias due to question wording.</p>
<p><strong>response variable</strong><br>
Variable that measures the outcome of a study.</p>
<p><strong>explanatory variable</strong><br>
Variable that may help predict or explain changes in a response variable.</p>
<p><strong>confounding</strong><br>
When two variables are associated in such a way that their effects on a response variable cannot be distinguished from each other.</p>
<p><strong>confounding variable</strong><br>
A variable related to both the explanatory variable and the response variable in a study that may create the false impression of a cause-and-effect relationship between the explanatory and response variables.</p>
<p><strong>treatment</strong><br>
Specific condition applied to the individuals in an experiment. If an experiment has several explanatory variables, a treatment is a combination of specific values of these variables.</p>
<p><strong>experimental unit</strong><br>
The object to which a treatment is randomly assigned. When the experimental units are human beings, they are often called subjects.</p>
<p><strong>subjects</strong><br>
Experimental units that are human beings.</p>
<p><strong>placebo</strong><br>
A treatment that has no active ingredient but is otherwise like other treatments.</p>
<p><strong>factor</strong><br>
Explanatory variable in an experiment that is manipulated and may cause a change in the response variable.</p>
<p><strong>level</strong><br>
Specific value of an explanatory variable (factor) in an experiment.</p>
<p><strong>control group</strong><br>
Experimental group whose primary purpose is to provide a baseline for comparing the effects of the other treatments. Depending on the purpose of the experiment, a control group may be given an inactive treatment (placebo), an active treatment, or no treatment at all.</p>
<p><strong>placebo effect</strong><br>
Describes the fact that some subjects in an experiment will respond favorably to any treatment, even an inactive treatment (placebo).</p>
<p><strong>double-blind</strong><br>
An experiment in which neither the subjects nor those who interact with them and measure the response variable know which treatment a subject is receiving.</p>
<p><strong>single-blind</strong><br>
An experiment in which either the subjects or the people who interact with them and measure the response variable don’t know which treatment a subject is receiving.</p>
<p><strong>random assignment</strong><br>
Experimental design principle. Use of a chance process to assign experimental units to treatments (or treatments to experimental units). Doing so helps create roughly equivalent groups of experimental units by balancing the effects of other variables among the treatment groups, allowing for cause-and-effect conclusions.</p>
<p><strong>completely randomized design</strong><br>
Design in which the experimental units are assigned to the treatments completely at random.</p>
<p><strong>replication</strong><br>
Experimental design principle. Giving each treatment to enough experimental units so that a difference in the effects of the treatments can be distinguished from chance variation due to the random assignment.</p>
<p><strong>control</strong><br>
Experimental design principle. Keeping variables (other than the explanatory variable) the same for all groups, especially variables that are likely to affect the response variable. Helps avoid confounding and reduces variability in the response variable.</p>
<p><strong>block</strong><br>
Group of experimental units that are known before the experiment to be similar in some way that is expected to affect the response to the treatments.</p>
<p><strong>randomized block design</strong><br>
Experimental design that forms groups (blocks) consisting of individuals that are similar in some way that is expected to affect the response to the treatments and then randomly assigns experimental units to treatments separately within each block.</p>
<p><strong>matched pairs design</strong><br>
Common experimental design for comparing two treatments that uses blocks of size 2. In some matched pairs designs, each subject receives both treatments in a random order. In others, two very similar experimental units are paired and the two treatments are randomly assigned within each pair.</p>
<p><strong>statistically significant</strong><br>
In an experiment, when the difference in responses between the groups is so large that it is unlikely to be explained by the chance variation in the random assignment, the results are called statistically significant.</p>
</section>
<section id="unit-4" class="level1">
<h1>Unit 4</h1>
<p><strong>random process</strong><br>
Generates outcomes that are determined purely by chance.</p>
<p><strong>probability</strong><br>
A number between 0 and 1 that describes the proportion of times an outcome of a random process would occur in a very long series of trials.</p>
<p><strong>law of large numbers</strong><br>
If we observe more and more trials of any random process, the proportion of times that a specific outcome occurs approaches its probability.</p>
<p><strong>simulation</strong><br>
Imitation of a random process in such a way that simulated outcomes are consistent with real-world outcomes.</p>
<p><strong>probability model</strong><br>
Description of a random process that consists of two parts: a list of all possible outcomes and the probability of each outcome.</p>
<p><strong>sample space</strong><br>
List of all possible outcomes of a random process.</p>
<p><strong>event</strong><br>
A subset of the possible outcomes from the sample space of a random process. Events are usually designated by capital letters, like A, B, C, and so on.</p>
<p><strong>complement rule</strong><br>
The probability that an event does not occur is 1 minus the probability that the event does occur. In symbols, P(Aᶜ) = 1 − P(A).</p>
<p><strong>complement</strong><br>
The complement of event A, written as Aᶜ, is the event that A does not occur.</p>
<p><strong>mutually exclusive</strong><br>
Two events A and B that have no outcomes in common and so can never occur together. That is, P(A and B) = 0.</p>
<p><strong>addition rule for mutually exclusive events</strong><br>
If A and B are mutually exclusive events, P(A or B) = P(A) + P(B).</p>
<p><strong>general addition rule</strong><br>
If A and B are any two events resulting from the same random process, then the probability that event A or event B (or both) occur is P(A or B) = P(A∪B) = P(A) + P(B) - P(A∩B).</p>
<p><strong>Venn diagram</strong><br>
A figure that consists of one or more circles surrounded by a rectangle. Each circle represents an event. The region inside the rectangle represents the sample space of the random process.</p>
<p><strong>intersection</strong><br>
The event “A and B” is called the intersection of events A and B. It consists of all outcomes that are common to both events, and is denoted by A∩B.</p>
<p><strong>union</strong><br>
The event “A or B” is called the union of events A and B. It consists of all outcomes that are in event A, event B, or both, and is denoted by A∪B.</p>
<p><strong>conditional probability</strong><br>
Probability that one event happens given that another event is already known to have happened. The probability that event A happens given that event B has happened is denoted by P(A|B).</p>
<p><strong>independent events</strong><br>
Two events are independent if knowing whether or not one event has occurred does not change the probability that the other event will happen. In other words, events A and B are independent if P(A|B) = P(A|Bᶜ) = P(A) and P(B|A) = P(B|Aᶜ) = P(B).</p>
<p><strong>general multiplication rule</strong><br>
For any random process, the probability that events A and B both occur can be found using the formula P(A and B) = P(A∩B) = P(A) * P(B|A).</p>
<p><strong>tree diagram</strong><br>
A diagram that shows the sample space of a random process involving multiple stages. The probability of each outcome is shown on the corresponding branch of the tree. All probabilities after the first stage are conditional probabilities.</p>
<p><strong>multiplication rule for independent events</strong><br>
If A and B are independent events, then the probability that A and B both occur is P(A and B) = P(A∩B) = P(A) * P(B).</p>
<p><strong>random variable</strong><br>
Variable that takes numerical values that describe the outcomes of a random process.</p>
<p><strong>probability distribution</strong><br>
Gives the possible values of a random variable and their probabilities. Gives the possible values of a random variable and their probabilities.</p>
<p><strong>discrete random variable</strong><br>
Variable that takes a countable set of possible values with gaps between them on a number line. The probability of any event is the sum of the probabilities for the values of the variable that make up the event.</p>
<p><strong>mean (expected value) of a discrete random variable</strong><br>
Describes the variable’s long-run average value over many, many trials of the same random process.</p>
<p><strong>standard deviation of a discrete random variable</strong><br>
Measures how much the values of the random variable typically vary from the mean in many, many trials of the random process.</p>
<p><strong>independent random variables</strong><br>
If knowing the value of X does not help us predict the value of Y, then X and Y are independent random variables. In other words, two random variables are independent if knowing the value of one variable does not change the probability distribution of the other variable.</p>
<p><strong>binomial setting</strong><br>
Arises when we perform n independent trials of the same random process and count the number of times that a particular outcome (called a “success”) occurs. The four conditions for a binomial setting are: Binary? The possible outcomes of each trial can be classified as “success” or “failure.” Independent? Trials must be independent. That is, knowing the outcome of one trial must not tell us anything about the outcome of any other trial. Number? The number of trials n of the random process must be fixed in advance. Same probability? There is the same probability p of success on each trial.</p>
<p><strong>binomial random variable</strong><br>
The count of successes X in a binomial setting. The possible values of X are 0, 1, 2, . . . , n.</p>
<p><strong>binomial distribution</strong><br>
In a binomial setting, suppose we let X = the number of successes. The probability distribution of X is a binomial distribution with parameters n and p, where n is the number of trials of the random process and p is the probability of a success on each trial.</p>
<p><strong>binomial coefficient</strong><br>
The number of ways to arrange x successes among n trials.</p>
<p><strong>10% condition</strong><br>
When selecting a random sample of size n (without replacement) from a population of size N, we can treat individual observations as independent when performing calculations as long as n &lt; 0.10N.</p>
<p><strong>geometric setting</strong><br>
Arises when we perform independent trials of the same random process and record the number of trials it takes to get one success. On each trial, the probability p of success must be the same.</p>
<p><strong>geometric random variable</strong><br>
The number of trials X that it takes to get a success in a geometric setting. The possible values of X are 1, 2, 3, . . . .</p>
<p><strong>geometric distribution</strong><br>
In a geometric setting, suppose we let X = the number of trials it takes to get a success. The probability distribution of X is a geometric distribution with parameter p, the probability of a success on any trial.</p>
</section>
<section id="unit-5" class="level1">
<h1>Unit 5</h1>
<p><strong>continuous random variable</strong><br>
Variable that can take any value in a specified interval on the number line. Continuous random variables are modeled by density curves.</p>
<p><strong>density curve</strong><br>
Models the probability distribution of a continuous random variable with a curve that (a) is always on or above the horizontal axis and (b) has area exactly 1 underneath it. The area under the curve and above any specified interval of values on the horizontal axis gives the probability that the random variable falls within that interval.</p>
<p><strong>normal random variable</strong><br>
A continuous random variable whose probability distribution is described by a normal curve.</p>
<p><strong>statistic</strong><br>
Number that describes some characteristic of a sample.</p>
<p><strong>parameter</strong><br>
A number that describes some characteristic of a population.</p>
<p><strong>sampling variability</strong><br>
The fact that different random samples of the same size from the same population produce different values for an estimate (statistic).</p>
<p><strong>sampling distribution</strong><br>
The distribution of values taken by a statistic in all possible samples of the same size from the same population.</p>
<p><strong>unbiased estimator</strong><br>
A statistic used for estimating a parameter is unbiased if the mean of its sampling distribution is equal to the value of the parameter being estimated. The mean of the sampling distribution is also known as the expected value of the estimator.</p>
<p><strong>sampling distribution of a sample proportion ρ̂</strong></p>
<p>The distribution of values taken by the sample proportion ρ̂ in all possible samples of the same size from the same population.</p>
<p><strong>Large Counts condition</strong><br>
Let ρ̂ be the proportion of successes in a random sample of size n from a population with proportion of successes p.&nbsp;The Large Counts condition says that the sampling distribution of ρ̂ will be approximately normal when np ≥ 10 and n(1 - p) ≥ 10.</p>
<p><strong>sampling distribution of a sample mean x</strong></p>
<p>The distribution of values taken by the sample mean x in all possible samples of the same size from the same population.</p>
<p><strong>central limit theorem (CLT)</strong><br>
In an SRS of size n from any population with mean μ and finite standard deviation σ, when n is sufficiently large, the sampling distribution of the sample mean x is approximately normal.</p>
</section>
<section id="unit-6" class="level1">
<h1>Unit 6</h1>
<p><strong>point estimate</strong><br>
Specific value of a point estimator from a sample.</p>
<p><strong>point estimator</strong><br>
Statistic that provides an estimate of a population parameter.</p>
<p><strong>confidence interval</strong><br>
Gives a set of plausible values for a parameter based on sample data. Confidence intervals have the form, point estimate ± margin of error, or alternatively, statistic ± (critical value)(standard error of statistic).</p>
<p><strong>confidence level C</strong></p>
<p>Gives the approximate percentage of confidence intervals that will capture the population parameter in repeated random sampling with the same sample size.</p>
<p><strong>margin of error</strong><br>
Describes how far, at most, we expect the point estimate to vary from the population parameter. That is, the difference between the point estimate and the population parameter will be less than the margin of error in C% of all samples, where C is the confidence level.</p>
<p><strong>critical value</strong><br>
Multiplier that makes a confidence interval wide enough to have the stated capture rate. The critical value depends on both the confidence level C and the sampling distribution of the statistic.</p>
<p><strong>standard error of ρ̂</strong></p>
<p>The standard error describes how much the sample proportion ρ̂ typically varies from the population proportion p in repeated random samples of size n.</p>
<p><strong>one-sample z interval for a proportion</strong></p>
<p>Confidence interval used to estimate a population proportion p.</p>
<p><strong>significance test</strong><br>
Formal procedure for using observed data to decide between two competing claims (the null hypothesis and the alternative hypothesis). The claims are usually statements about parameters. Also called a test of significance, a hypothesis test, or a test of hypotheses.</p>
<p><strong>null hypothesis H₀</strong></p>
<p>Claim we weigh evidence against in a significance test. Often the null hypothesis is a statement of “no difference.”</p>
<p><strong>alternative hypothesis Hₐ</strong></p>
<p>The claim that we are trying to find evidence for in a significance test.</p>
<p><strong>one-sided alternative hypothesis</strong><br>
An alternative hypothesis is one-sided if it states that a parameter is greater than the null value or if it states that the parameter is less than the null value. Tests with a one-sided alternative hypothesis are sometimes called one-sided tests or one-tailed tests.</p>
<p><strong>two-sided alternative hypothesis</strong><br>
The alternative hypothesis is two-sided if it states that the parameter is different from the null value (it could be either greater than or less than). Tests with a two-sided alternative hypothesis are sometimes called two-sided tests or two-tailed tests.</p>
<p><strong>P-value</strong></p>
<p>The probability of getting evidence for the alternative hypothesis Hₐ as strong as or stronger than the observed evidence when the null hypothesis H₀ is true. The smaller the P-value, the stronger the evidence against H₀ and in favor of Hₐ provided by the data.</p>
<p><strong>significance level α</strong><br>
Value that we use as a boundary to decide if an observed result is unlikely to happen by chance alone when the null hypothesis is true. The significance level gives the probability of a Type I error.</p>
<p><strong>standardized test statistic</strong><br>
Value that measures how far a sample statistic is from what we would expect if the null hypothesis H₀ were true, in standard deviation units.</p>
<p><strong>one-sample z test for a proportion</strong></p>
<p>A significance test of the null hypothesis that a population proportion p is equal to a specified value.</p>
<p><strong>Type I error</strong><br>
An error that occurs if we reject H₀ when H₀ is true. That is, the data give convincing evidence that Hₐ is true when it really isn’t.</p>
<p><strong>Type II error</strong><br>
An error that occurs if we fail to reject H₀ when Hₐ is true. That is, the data do not give convincing evidence that Hₐ is true when it really is.</p>
<p><strong>power</strong><br>
The probability that a test will find convincing evidence for Hₐ when a specific alternative value of the parameter is true. The power of a test against any alternative is 1 minus the probability of a Type II error for that alternative; that is, power = 1 - P(Type II error).</p>
<p><strong>two-sample z interval for a difference in proportions</strong></p>
<p>Confidence interval used to estimate a difference in the proportions of successes for two populations or treatments.</p>
<p><strong>two-sample z test for the difference in proportions</strong></p>
<p>A significance test of the null hypothesis that the difference in the proportions of successes for two populations or treatments is equal to a specified value (usually 0).</p>
</section>
<section id="unit-7" class="level1">
<h1>Unit 7</h1>
<p><strong>t distribution</strong></p>
<p>A distribution described by a symmetric, single-peaked, bell-shaped density curve centered at 0 that is completely specified by its degrees of freedom (df) and has more area in its tails than the standard normal distribution. When performing inference about a population mean μ based on a random sample of size n using the sample standard deviation sx to estimate the population standard deviation σ, use a t distribution with df = n − 1.</p>
<p><strong>standard error of the sample mean x</strong></p>
<p>The standard error of x estimates how much the sample mean x typically varies from the population mean μ in repeated random samples of size n.</p>
<p><strong>one-sample t interval for a mean</strong></p>
<p>Confidence interval used to estimate a population mean μ when the population standard deviation σ is unknown.</p>
<p><strong>paired data</strong><br>
The result of recording two values of the same quantitative variable for each individual or for each pair of similar individuals.</p>
<p><strong>paired t interval for a mean difference</strong></p>
<p>Confidence interval used with paired data to estimate a population mean difference.</p>
<p><strong>one-sample t test for a mean</strong></p>
<p>A significance test of the null hypothesis that a population mean μ is equal to a specified value, when the population standard deviation σ is unknown.</p>
<p><strong>paired t test for a mean difference</strong></p>
<p>A significance test of the null hypothesis that a population mean difference is equal to a specified value, usually 0.</p>
<p><strong>two-sample t interval for a difference in means</strong></p>
<p>Confidence interval used to estimate a difference in the means of two populations or treatments, when both population standard deviations are unknown.</p>
<p><strong>two-sample t test for a difference in means</strong></p>
<p>A significance test of the null hypothesis that the difference in the means of two populations or treatments is equal to a specified value (usually 0), when both population standard deviations are unknown.</p>
</section>
<section id="unit-8" class="level1">
<h1>Unit 8</h1>
<p><strong>chi-square test statistic</strong><br>
Measure of how far the observed counts are from the expected counts relative to the expected counts.</p>
<p><strong>chi-square distribution</strong><br>
A distribution that is defined by a density curve that takes only nonnegative values and is skewed to the right. A particular chi-square distribution is specified by giving its degrees of freedom.</p>
<p><strong>chi-square test for goodness of fit</strong><br>
A significance test of the null hypothesis that a categorical variable has a specified distribution in the population of interest.</p>
<p><strong>chi-square test for independence</strong><br>
A significance test of the null hypothesis that there is no association between two categorical variables in the population of interest.</p>
<p><strong>chi-square test for homogeneity</strong><br>
A significance test of the null hypothesis that there is no difference in the distributions of a categorical variable in the populations of interest or for the treatments in an experiment.</p>
</section>
<section id="unit-9" class="level1">
<h1>Unit 9</h1>
<p><strong>population regression line</strong><br>
Regression line μy = α + βx calculated from every value in the population.</p>
<p><strong>sample regression line</strong><br>
Least-squares regression line ŷ = a + bx computed from sample data.</p>
<p><strong>t interval for the slope</strong></p>
<p>Confidence interval used to estimate the slope β of a population regression line.</p>
<p><strong>t test for the slope</strong></p>
<p>A significance test of the null hypothesis that the slope β of a population regression line is equal to a specified value, most commonly 0.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer>© 2025 Thomas Abraham</footer>
</body></html>